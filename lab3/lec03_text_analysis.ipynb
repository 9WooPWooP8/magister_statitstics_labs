{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ce4kspARRQaP"
   },
   "source": [
    "# Анализ текстовых данных - Natural Language Processing, NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvmRO2gtRVkR"
   },
   "source": [
    "## Предварительная обработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8UzEGkHRcGz"
   },
   "source": [
    "### Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvgls1wZQ-sb",
    "outputId": "4ea6d0bf-c417-430f-bb79-9e2e2393b744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df = 1)\n",
    "print (vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLtQe38urR2l"
   },
   "source": [
    "### Векторизация корпуса из двух документов\n",
    "Корпус задан как список строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yO9whlODSRBV",
    "outputId": "8d196855-6f2f-4601-9bc0-1692b3966c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape -> (число документов, длина словаря)\n",
      "(2, 7)\n",
      "Результат векторизации:\n",
      "  (0, 3)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "test_content = ['How to format my hard disk', 'Hard disk format problems']\n",
    "# векторизация\n",
    "X = vectorizer.fit_transform(test_content)\n",
    "print ('shape -> (число документов, длина словаря)')\n",
    "print(X.shape)\n",
    "print('Результат векторизации:')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osTfhSonXdz0"
   },
   "source": [
    "Получим словарь корпуса (по алфавиту)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdMQPyJ2S5SE",
    "outputId": "faf384b4-56df-446c-effa-72ffaaf6a7a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['disk', 'format', 'hard', 'how', 'my', 'problems', 'to'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sw7q_jj1pIE"
   },
   "source": [
    "## Пример с корпусом текстов сообщений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5R8YIycXjTq"
   },
   "source": [
    "Используем учебный датасет https://www.kaggle.com/crawford/20-newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "murXoKy-s59M"
   },
   "source": [
    "В нем около 18 000 документов (посты в группах), отнесенных к 20 группам-категориям.\n",
    "\n",
    "Можно легко выбирать отдельные категории (см.далее)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "059vPbIXVub4"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti2ibluSX4x1"
   },
   "source": [
    "Как можно взять часть данных? Явно указать названия категорий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLPQWnpwVyQq",
    "outputId": "53b43585-47be-445c-b412-d1dedad9345f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961 documents\n",
      "2 categories\n"
     ]
    }
   ],
   "source": [
    "categories = ['comp.graphics','comp.windows.x']\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=4)\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgiLSKUrYBMg"
   },
   "source": [
    "Возьмем первые 50 документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfHeIVV3q9OA",
    "outputId": "dc4a817b-a441-445b-c0a3-11d6fb5b2995"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From: joshuaf@yang.earlham.edu\\nSubject: Re: TIFF -> Anything?!\\nOrganization: Earlham College, Richmond, Indiana\\nLines: 15\\n\\nIn article <1993Apr23.033843.26854@spartan.ac.BrockU.CA>, tmc@spartan.ac.BrockU.CA (Tim Ciceran) writes:\\n> There is a program called Graphic Workshop you can FTP from\\n> wuarchive.  The file is in the msdos/graphics directory and\\n> is called \"grfwk61t.zip.\"  This program should od everthing\\n> you need.\\n> \\n> -- \\n> \\n> TMC\\n> (tmc@spartan.ac.BrockU.ca)\\n\\n\\nTHANKS!  It did work, and it is just what I needed thanks...\\n\\nJoshuaf\\n',\n",
       " 'From: dealy@narya.gsfc.nasa.gov (Brian Dealy - CSC)\\nSubject: Re: Monthly Question about XCopyArea() and Expose Events\\nOrganization: NASA/Goddard Space Flight Center\\nLines: 43\\nDistribution: world\\nNNTP-Posting-Host: narya.gsfc.nasa.gov\\nOriginator: dealy@narya.gsfc.nasa.gov\\n\\n\\n|> (2nd posting of the question that just doesn\\'t seem to get answered)\\n|> \\n|> Suppose you have an idle app with a realized and mapped Window that contains\\n|> Xlib graphics.  A button widget, when pressed, will cause a new item\\n|> to be drawn in the Window.  This action clearly should not call XCopyArea() \\n|> (or equiv) directly; instead, it should register the existence of the new\\n|> item in a memory structure and let the same expose event handler that handles\\n|> \"regular\" expose events (e.g. window manager-driven exposures) take care\\n|> of rendering the new image.  Using an expose event handler is a \"proper\" way\\n|> to do this because at the time the handler is called, the Xlib Window is\\n|> guaranteed to be mapped.\\n|> \\n|> The problem, of course, is that no expose event is generated if the window\\n|> is already visible and mapped.  What we need to do is somehow \"tickle\" the\\n|> Window so that the expose handler is hit with arguments that will enable\\n|> it to render *just* the part of the window that contains the new item.\\n|> \\n|> What is the best way to tickle a window to produce this behavior?\\n\\nIf I understand your problem correctly, you want to have a way to send\\nexposures to your manager widget when your app-specific code draws xlib\\ngraphics on the window.\\n\\nIt sounds like you might want to send an exposure using\\nXSendEvent and specifying a region. If you know the region you need to\\nsend the exposure, generally you have the bounding rectangle of the objects,\\nyou can use XCreateRegion to create a region, XUnionRectWithRegion to add the\\nnew object polygons to the region, and then either use the region\\nto clip your GC for the redraw or use XRectInRegion to test which of your\\nother objects need to be redrawn. Keeping in mind that the stacking order\\nof overlapping objects affects how they look.\\n\\nHope it helps\\n\\n-- \\nBrian Dealy                |301-572-8267| It not knowing where it\\'s at  \\ndealy@kong.gsfc.nasa.gov   |            | that\\'s important,it\\'s knowing\\n!uunet!dftsrv!kong!dealy   |            | where it\\'s not at...  B.Dylan\\n-- \\nBrian Dealy                |301-572-8267| It not knowing where it\\'s at  \\ndealy@kong.gsfc.nasa.gov   |            | that\\'s important,it\\'s knowing\\n!uunet!dftsrv!kong!dealy   |            | where it\\'s not at...  B.Dylan\\n',\n",
       " 'From: perrot@grbb.polymtl.ca (Gildas PERROT)\\nSubject: Installing xdbx v2.1.2 on SGI \\nOriginator: perrot@indigo\\nOrganization: Ecole Polytechnique, Institut de Genie Biomedical\\nLines: 10\\n\\n\\nDid anyone install xdbx v2.1.2 on SGI workstation ?\\n\\n\\nThanks for your answer.\\t\\tGildas PERROT.\\n-- \\n# Gildas PERROT, Associe de recherche # Ecole Polytechnique\\t#      \\n# Institut de Genie Biomedical        # C.P. 6079, Succ. A      # \\n# e-mail: perrot@grbb.polymtl.ca      #\\tMontreal H3C3A7, Canada #\\n# Tel: (514) 340-4183                 # Fax: (514) 340-4611     #           \\n',\n",
       " 'From: joerg@sax.sax.de (Joerg Wunsch)\\nSubject: About the various DXF format questions\\nOrganization: SaxNet, Dresden, Germany\\nLines: 25\\nDistribution: world\\nNNTP-Posting-Host: sax.sax.de\\nSummary: List of sites holding documentation of DXF format\\nKeywords: DXF, graphics formats\\n\\nArchie told me the following sites holding documentation about DXF:\\n\\nHost nic.funet.fi   (128.214.6.100)\\nLast updated 15:11  7 Apr 1993\\n\\n    Location: /pub/csc/graphics/format\\n      FILE      rwxrwxr--     95442  Dec  4  1991   dxf.doc\\n\\nHost rainbow.cse.nau.edu   (134.114.64.24)\\nLast updated 17:09  1 Jun 1992\\n\\n    Location: /graphics/formats\\n      FILE      rw-r--r--     95442  Mar 23 23:31   dxf.doc\\n\\nHost ftp.waseda.ac.jp   (133.9.1.32)\\nLast updated 00:47  5 Apr 1993\\n\\n    Location: /pub/data/graphic\\n      FILE      rw-r--r--     39753  Nov 18  1991   dxf.doc.Z\\n\\n-- \\nJ\"org Wunsch, ham: dl8dtl    : joerg_wunsch@uriah.sax.de\\nIf anything can go wrong...  :   ...or:\\n     .o .o                   : joerg@sax.de,wutcd@hadrian.hrz.tu-chemnitz.de,\\n       <_      ... IT WILL!  : joerg_wunsch@tcd-dresden.de\\n',\n",
       " 'From: sherman@unx.sas.com (Chris Sherman)\\nSubject: Re: POVray : tga -> rle\\nNntp-Posting-Host: workroom.unx.sas.com\\nOrganization: SAS Institute Inc.\\nLines: 77\\n\\nIn <1rkkb6$gec@st-james.comp.vuw.ac.nz> Craig.Humphrey@comp.vuw.ac.nz (Craig Andrew Humphrey) writes:\\n\\n\\n>In article <ltqp28INNpa7@pageboy.cs.utexas.edu>, jhpark@cs.utexas.edu (Jihun Park) writes:\\n>>Hello,\\n>>I have some problem in converting tga file(generated by POVray) to\\n>>rle file. When I convert, I do not get any warning message. But\\n>>if I use xloadimage/getx11, something is wrong.\\n\\n>[edited]\\n\\n>>I know that I need to install ppmtorle and tgatoppm, but I do not spend\\n>>time to install them. Even I do not want to generate .rgb from POVray\\n>>and then convert them to rle, if possible.(.rgb to rle works, but\\n>>it will mess up my directory with so many files, and it needs 2 more\\n>>steps to finally convert to rle file. say cat | rawtorle | rleflip )\\n>>Does any body out there have same experience/problems ?\\n\\n\\n>Well for starters, why use rle files?  \\n\\nExactly...\\n\\nI didn\\'t want to mess with tga or rle.  So I wrote the following script. \\nAll you need is the very standard set of pbm utilities. \\n\\nThis script is a .pov to .jpg converter.  Just run it like this:\\n\\n  pov2jpg 1280 1024 fred.pov \\n\\nYou will need to modify the path\\'s in the script to reflect where you put\\npovray and its include files.  If you have a problem with disk space, you\\ncan use named pipes instead of temporary files.\\n\\nI hope you find it useful...\\n\\n----------------------------------------------------------------------------\\n\\n#!/bin/sh\\n\\nif [ $# -lt 3 ] ; then\\n  echo \"usage:  $0 width height sourcefile.pov other_options\"\\n  exit\\nfi\\n\\nwidth=$1\\nheight=$2\\ndatafile=$3\\nshift 3\\n\\n#basedatafile=`echo $datafile | sed -e \"s/\\\\(.*\\\\)\\\\.pov/\\\\1/\"`\\n\\nthedatafile=`basename $datafile` \\nbasedatafile=`basename $datafile .pov` \\ndirdatafile=`dirname $datafile` \\n\\ncd $dirdatafile\\n/afs/rnd.sas.com/u/sherman/pov/povsrc/build/povray \\\\\\n  +l/afs/rnd.sas.com/u/sherman/pov/povscn/include \\\\\\n  +o/tmp/data$$ +w${width} +h${height} +fr +i${thedatafile} $*\\n\\necho \" \"\\nrawtopgm $width $height < /tmp/data$$.grn > /tmp/green$$\\nrawtopgm $width $height < /tmp/data$$.red > /tmp/red$$\\nrawtopgm $width $height < /tmp/data$$.blu > /tmp/blue$$\\nrgb3toppm /tmp/red$$ /tmp/green$$ /tmp/blue$$ | cjpeg > ${basedatafile}.jpg \\nrm /tmp/red$$ /tmp/green$$ /tmp/blue$$ /tmp/data$$.grn /tmp/data$$.red \\\\\\n   /tmp/data$$.blu\\necho \"Wrote output to ${basedatafile}.jpg\"\\n\\n---------------------------------------------------------------------------\\n\\n--\\n     ____/     /     /     __  /    _  _/    ____/\\n    /         /     /     /   /      /     /          Chris Sherman\\n   /         ___   /        _/      /          /\\n _____/   __/   __/   __/ _\\\\    _____/   _____/           sherman@unx.sas.com\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = dataset.data[:50]\n",
    "# полезно посмотреть на исходные тексты\n",
    "posts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1pUH3dyYHzF"
   },
   "source": [
    "### Векторизация\n",
    "Выведем результаты - число документов и длину словаря, которая определяет длину полученных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "im2i6tXasTsg",
    "outputId": "3465754c-8ad2-4b26-e468-153cb057d410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ns= 50, nf= 4595\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df = 1)\n",
    "X_train = vectorizer.fit_transform(posts)\n",
    "# число сообщений, длина словаря\n",
    "num_samples, num_features = X_train.shape\n",
    "print ('ns= %d, nf= %d' % (num_samples, num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SbfoRpf4DIs"
   },
   "source": [
    "Вывод словаря для выбранных документов - видно, что есть токены, не имеющие особого смысла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kicvCI-Ps1v3",
    "outputId": "314bc9e4-0a4a-48c3-8f0d-a76051bc3680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '000005102000' ... 'zoyd' 'zurich' 'zyeh']\n"
     ]
    }
   ],
   "source": [
    "print (vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuWPIFe12NzF"
   },
   "source": [
    "### Поиск \"похожих\" документов\n",
    "Зададим произвольный текст вопроса и векторизуем его на основе имеющегося словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_eNFQRv9tmeu",
    "outputId": "2251fea8-579a-4fd9-e79d-0040f1ad3b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1812)\t2\n",
      "  (0, 2175)\t1\n",
      "  (0, 2260)\t1\n",
      "  (0, 2976)\t1\n",
      "  (0, 3530)\t1\n",
      "  (0, 4391)\t1\n",
      "  (0, 4593)\t1\n"
     ]
    }
   ],
   "source": [
    "# векторизация сообщения-вопроса\n",
    "new_post = 'Who is from Richmond Indiana or from Zurich'\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "print (new_post_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jvHKlGKwKk6"
   },
   "source": [
    "Все слова есть в словаре -> можно найти \"похожие\" документы!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af3C7dH_2den"
   },
   "source": [
    "### Подготовка для вычисления расстояний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Im00rslwo-I"
   },
   "source": [
    "Построим метрику напрямую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "_kLGbKpZzFif"
   },
   "outputs": [],
   "source": [
    "# функция для евклидова расстояния\n",
    "import scipy as sp\n",
    "def dist_eucl(v1, v2):\n",
    "    delta = v1 - v2\n",
    "    return sp.linalg.norm(delta.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TStaysCJ2xqC"
   },
   "source": [
    "Поиск ближайшего сообщения с промежуточной печатью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDz-mpz3zQSg",
    "outputId": "debcc163-ffbe-49d3-d0cb-f6cf09f471c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist=11.66\n",
      "dist=49.07\n",
      "dist=12.00\n",
      "dist=18.89\n",
      "dist=37.58\n",
      "dist=15.81\n",
      "dist=19.05\n",
      "dist=9.38\n",
      "dist=12.49\n",
      "dist=12.33\n",
      "dist=8.00\n",
      "dist=36.61\n",
      "dist=18.08\n",
      "dist=25.42\n",
      "dist=34.50\n",
      "dist=29.41\n",
      "dist=14.14\n",
      "dist=13.45\n",
      "dist=12.33\n",
      "dist=19.87\n",
      "dist=10.54\n",
      "dist=774.36\n",
      "dist=540.17\n",
      "dist=8.31\n",
      "dist=19.47\n",
      "dist=30.84\n",
      "dist=19.70\n",
      "dist=16.43\n",
      "dist=23.28\n",
      "dist=22.36\n",
      "dist=13.45\n",
      "dist=31.13\n",
      "dist=40.68\n",
      "dist=18.36\n",
      "dist=75.22\n",
      "dist=20.22\n",
      "dist=10.86\n",
      "dist=142.25\n",
      "dist=33.06\n",
      "dist=8.37\n",
      "dist=19.54\n",
      "dist=7.35\n",
      "dist=28.88\n",
      "dist=21.73\n",
      "dist=27.15\n",
      "dist=10.30\n",
      "dist=9.06\n",
      "dist=25.36\n",
      "dist=28.34\n",
      "dist=24.62\n",
      "best post is 41 dist=7.35\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# поиск ближайшего сообщения\n",
    "best_post = []\n",
    "best_dist = sys.maxsize\n",
    "best_i = 0\n",
    "for i in range(0, num_samples):\n",
    "  post_vec = X_train.getrow(i)\n",
    "  d = dist_eucl(post_vec, new_post_vec)\n",
    "  print('dist=%.2f'%d)\n",
    "  if d < best_dist:\n",
    "    best_dist = d\n",
    "    best_i = i\n",
    "print ('best post is %i dist=%.2f' % (best_i, best_dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hY-otBfyz7F-",
    "outputId": "a2011211-2cae-429e-c1f0-1d0f85465424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: queloz@bernina.ethz.ch (Ronald Queloz)\n",
      "Subject: Hypercard for UNIX\n",
      "Organization: Swiss Federal Institute of Technology (ETH), Zurich, CH\n",
      "Lines: 10\n",
      "\n",
      "Hi netlanders,\n",
      "\n",
      "Does anybody know if there is something like Macintosh Hypercard for any UNIX \n",
      "platform?\n",
      "\n",
      "\n",
      "Thanks in advance\n",
      "\n",
      "\n",
      "Ron.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(posts[best_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gXEM4a-3bfF"
   },
   "source": [
    "Нормируем векторы сообщений к длине=1 и изменим функцию для расстояния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "PLNI80KU3jNP"
   },
   "outputs": [],
   "source": [
    "# переход к расстоянию между нормированными векторами\n",
    "def dist_norm(v1, v2):\n",
    "    v1_norm = v1/sp.linalg.norm(v1.toarray())\n",
    "    v2_norm = v2/sp.linalg.norm(v2.toarray())\n",
    "    delta = v1_norm - v2_norm\n",
    "    return sp.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CX5zqIwf3nPO",
    "outputId": "3108466e-449f-4b19-bdfc-cb759f504b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist=1.22\n",
      "dist=1.38\n",
      "dist=1.37\n",
      "dist=1.34\n",
      "dist=1.28\n",
      "dist=1.35\n",
      "dist=1.38\n",
      "dist=1.35\n",
      "dist=1.30\n",
      "dist=1.34\n",
      "dist=1.35\n",
      "dist=1.30\n",
      "dist=1.39\n",
      "dist=1.34\n",
      "dist=1.35\n",
      "dist=1.33\n",
      "dist=1.36\n",
      "dist=1.36\n",
      "dist=1.35\n",
      "dist=1.38\n",
      "dist=1.34\n",
      "dist=1.29\n",
      "dist=1.33\n",
      "dist=1.28\n",
      "dist=1.33\n",
      "best post is 0 dist=1.22\n"
     ]
    }
   ],
   "source": [
    "# поиск ближайшего сообщения\n",
    "best_post = None\n",
    "best_dist = sys.maxsize\n",
    "best_i = None\n",
    "for i in range(0, num_samples):\n",
    "  post_vec = X_train.getrow(i)\n",
    "  d = dist_norm(post_vec, new_post_vec)\n",
    "  if i%2==0:\n",
    "    print('dist=%.2f'%d)\n",
    "  if d < best_dist:\n",
    "    best_dist = d\n",
    "    best_i = i\n",
    "print ('best post is %i dist=%.2f' % (best_i, best_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdouDdwf4O-W",
    "outputId": "5b2a0b96-7b3e-47d1-b4bc-a9b7e44fc0fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: joshuaf@yang.earlham.edu\n",
      "Subject: Re: TIFF -> Anything?!\n",
      "Organization: Earlham College, Richmond, Indiana\n",
      "Lines: 15\n",
      "\n",
      "In article <1993Apr23.033843.26854@spartan.ac.BrockU.CA>, tmc@spartan.ac.BrockU.CA (Tim Ciceran) writes:\n",
      "> There is a program called Graphic Workshop you can FTP from\n",
      "> wuarchive.  The file is in the msdos/graphics directory and\n",
      "> is called \"grfwk61t.zip.\"  This program should od everthing\n",
      "> you need.\n",
      "> \n",
      "> -- \n",
      "> \n",
      "> TMC\n",
      "> (tmc@spartan.ac.BrockU.ca)\n",
      "\n",
      "\n",
      "THANKS!  It did work, and it is just what I needed thanks...\n",
      "\n",
      "Joshuaf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(posts[best_i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdkwpbom3f6d"
   },
   "source": [
    "### Как влияют стоп-слова?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdTY1LFN5HUx"
   },
   "source": [
    "Убираем стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qN9HvhdW5NTc",
    "outputId": "45362420-8cd5-4360-8882-983f74d28380"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df = 1, stop_words = 'english')\n",
    "\n",
    "sorted(vectorizer.get_stop_words())[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_8wKN3X5nI9",
    "outputId": "6c7188c2-2ca5-423e-e89b-bce6f7f84c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ns= 50, nf= 4360\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(posts)\n",
    "# число сообщений, число слов\n",
    "num_samples, num_features = X_train.shape\n",
    "print ('ns= %d, nf= %d' % (num_samples, num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "jLSHpHXH5464"
   },
   "outputs": [],
   "source": [
    "new_post_vec = vectorizer.transform([new_post])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjvZQNI16Pqq",
    "outputId": "15ff7c8e-2e0f-498b-d39d-e428df4694d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist=1.33\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.37\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.35\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "dist=1.41\n",
      "best post is 0 dist=1.33\n"
     ]
    }
   ],
   "source": [
    "# поиск ближайшего сообщения\n",
    "best_post = None\n",
    "best_dist = sys.maxsize\n",
    "best_i = None\n",
    "for i in range(0, num_samples):\n",
    "  post_vec = X_train.getrow(i)\n",
    "  d = dist_norm(post_vec, new_post_vec)\n",
    "  # проверочная печать\n",
    "  print('dist=%.2f'%d)\n",
    "\n",
    "  if d < best_dist:\n",
    "    best_dist = d\n",
    "    best_i = i\n",
    "print ('best post is %i dist=%.2f' % (best_i, best_dist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eNLTQanKNkD"
   },
   "source": [
    "# Библиотека nltk - Natural Language Tool Kit\n",
    "https://www.nltk.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcUHs8fbKXBp"
   },
   "source": [
    "Стоп-слова для русского языка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ya_0ImbwKdxm",
    "outputId": "c2dc3e27-b119-4346-cc3c-333da54942fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('russian')\n",
    "print(stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWTLweDPMKjY"
   },
   "source": [
    "### Стемминг с помощью nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "wVv76tNMMS7j",
    "outputId": "d4fff684-fdfc-46e9-b33a-9de36d2345b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'imag'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.stem\n",
    "s=nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "s.stem('imaging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "zpSopmV2Ml-R",
    "outputId": "13870139-0ddb-4eb0-82ba-1682c19924f7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'imag'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "E9YPecBJMpQg",
    "outputId": "0dc01482-1bb5-46af-d480-afd713225ee5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'imagin'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem('imagination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "BOC1OPAdMxCO",
    "outputId": "bf9baafb-6c4a-4f72-b236-f7fcf66c499b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'домик'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=nltk.stem.SnowballStemmer('russian')\n",
    "\n",
    "s.stem('домик')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "qmOQRrXDM5qA",
    "outputId": "8437ae1b-5985-49b7-d260-9cbe9ef8ff88"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'дом'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem('дома')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rGj6Q86N2gp"
   },
   "source": [
    "# Векторизация TF-IDF\n",
    "Простой пример для прямого вычисления векторов весов в корпусе из трех токенизированных документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mh2ou7r_NFXk",
    "outputId": "f527b432-291f-4834-ed6f-50b0a2287832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.27031007207210955\n",
      "0.13515503603605478\n",
      "0.3662040962227032\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tfidf(t, d, D):\n",
    "    tf = float(d.count(t)) / sum(d.count(w) for w in set(d))\n",
    "    idf = np.lib.scimath.log(float(len(D)) / (len([doc for doc in D if t in doc])))\n",
    "    return tf * idf\n",
    "# документы\n",
    "a1, a2, a3 = ['a'], ['a', 'b', 'b'], ['a', 'b', 'c']\n",
    "# корпус\n",
    "D = [a1, a2, a3]\n",
    "print (tfidf('a', a1, D))\n",
    "print (tfidf('a', a2, D))\n",
    "print (tfidf('a', a3, D))\n",
    "print (tfidf('b', a2, D))\n",
    "print (tfidf('b', a3, D))\n",
    "print (tfidf('c', a3, D))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
